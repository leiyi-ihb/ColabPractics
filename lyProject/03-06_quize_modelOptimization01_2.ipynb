{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3Sl/D99W+AG4mRuy1k+BM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leiyi-ihb/ColabPractics/blob/main/lyProject/03-06_quize_modelOptimization01_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mk096DBoiwgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f21ab86-4edd-450b-aa70-73c9dfa6ebcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Platform:Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Tensorflow version:2.9.2\n",
            "Keras version:2.9.0\n"
          ]
        }
      ],
      "source": [
        "import platform\n",
        "import tensorflow\n",
        "import keras\n",
        "print(\"Platform:{}\".format(platform.platform()))\n",
        "print(\"Tensorflow version:{}\".format(tensorflow.__version__))\n",
        "print(\"Keras version:{}\".format(keras.__version__))\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv1D, MaxPool1D, GlobalMaxPool1D\n",
        "from keras.utils import plot_model\n",
        "from keras.optimizers import Adam, SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! -f \"dataset_Li.pkl\" ]; then wget https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl ; else echo \"Found previous downloaded data.\"; fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyQN7S8_kLUV",
        "outputId": "5444cf6e-e329-4906-e22c-938d89a5fa68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 16:21:13--  https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving master.dl.sourceforge.net (master.dl.sourceforge.net)... 216.105.38.12\n",
            "Connecting to master.dl.sourceforge.net (master.dl.sourceforge.net)|216.105.38.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl [following]\n",
            "--2022-11-12 16:21:13--  https://downloads.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving downloads.sourceforge.net (downloads.sourceforge.net)... 204.68.111.105\n",
            "Connecting to downloads.sourceforge.net (downloads.sourceforge.net)|204.68.111.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://gigenet.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl [following]\n",
            "--2022-11-12 16:21:13--  https://gigenet.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving gigenet.dl.sourceforge.net (gigenet.dl.sourceforge.net)... 69.65.16.142\n",
            "Connecting to gigenet.dl.sourceforge.net (gigenet.dl.sourceforge.net)|69.65.16.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640080470 (610M) [application/octet-stream]\n",
            "Saving to: ‘dataset_Li.pkl’\n",
            "\n",
            "dataset_Li.pkl      100%[===================>] 610.43M  23.2MB/s    in 27s     \n",
            "\n",
            "2022-11-12 16:21:41 (22.3 MB/s) - ‘dataset_Li.pkl’ saved [640080470/640080470]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing\n",
        "import pickle\n",
        "with open(\"dataset_Li.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "x_train, y_train = np.array(data['train'][0]), np.array(data['train'][1])\n",
        "x_test, y_test = np.array(data['test'][0]), np.array(data['test'][1])\n",
        "\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "Bk862UJakIAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800636cc-3c4a-485c-b746-5c1200c5596f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 1000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 去掉网络最后一层的'softmax'\n",
        "from keras.layers import Dropout\n",
        "input = Input(shape=(1000, 4), name='input')\n",
        "conv1d_1 = Conv1D(32, kernel_size=20, activation='relu', name='conv1d_1')(input)\n",
        "# drop_1 = Dropout(0.2, name='dropout_1')(conv1d_1)\n",
        "pool_1 = MaxPool1D(pool_size=4, name='pool_1')(conv1d_1)\n",
        "conv1d_2 = Conv1D(16, kernel_size=20, activation='relu', name='conv1d_2')(pool_1)\n",
        "# drop_2 =Dropout(0.2, name='dropout_2')(conv1d_2)\n",
        "pool_2 = MaxPool1D(pool_size=4, name='pool_2')(conv1d_2)\n",
        "\n",
        "conv1d_3 = Conv1D(8, kernel_size=20, activation='relu', name='conv1d_3')(pool_2)\n",
        "# drop_2 =Dropout(0.2, name='dropout_2')(conv1d_2)\n",
        "pool_3 = MaxPool1D(pool_size=4, name='pool_3')(conv1d_3)\n",
        "\n",
        "dense_1 = Dense(10, activation='relu', name='dense1')(pool_3)\n",
        "dense_2 = Dense(8, activation='relu', name='dense2')(dense_1)\n",
        "output = Dense(1, activation='tanh', name='output')(dense_2)\n",
        "\n",
        "model = Model(inputs=input, outputs=output)\n",
        "\n",
        "# 可视化\n",
        "# 1、打印网络\n",
        "print(model.summary())\n",
        "# 2、展示网络结构\n",
        "plot_model(model,to_file='multiple_inputs.png')\n",
        "Image('multiple_inputs.png')\n",
        "\n",
        "adam = Adam(lr=0.1)\n",
        "# compile\n",
        "model.compile(optimizer=\"sgd\",\n",
        "             metrics = ['acc'],\n",
        "             loss = 'binary_crossentropy')\n",
        "# training\n",
        "model.fit(x_train, y_train,\n",
        "                   epochs = 20,\n",
        "                   batch_size = 10,\n",
        "                   )\n",
        "\n",
        "loss, accuracy = model.evaluate(x_train, y_train)\n",
        "print(\"\\ntest loss:\", loss)\n",
        "print('accuracy:', accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test, y_test) #将我们的训练集也评估一下\n",
        "print(\"\\ntrain loss:\", loss)\n",
        "print('accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7DZv_DzlBud",
        "outputId": "362984c0-0741-4585-e74e-93275154e3e7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000, 4)]         0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 981, 32)           2592      \n",
            "                                                                 \n",
            " pool_1 (MaxPooling1D)       (None, 245, 32)           0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 226, 16)           10256     \n",
            "                                                                 \n",
            " pool_2 (MaxPooling1D)       (None, 56, 16)            0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 37, 8)             2568      \n",
            "                                                                 \n",
            " pool_3 (MaxPooling1D)       (None, 9, 8)              0         \n",
            "                                                                 \n",
            " dense1 (Dense)              (None, 9, 10)             90        \n",
            "                                                                 \n",
            " dense2 (Dense)              (None, 9, 8)              88        \n",
            "                                                                 \n",
            " output (Dense)              (None, 9, 1)              9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,603\n",
            "Trainable params: 15,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1600/1600 [==============================] - 29s 18ms/step - loss: 0.7192 - acc: 0.5036\n",
            "Epoch 2/20\n",
            "1600/1600 [==============================] - 29s 18ms/step - loss: 0.6943 - acc: 0.5015\n",
            "Epoch 3/20\n",
            "1600/1600 [==============================] - 29s 18ms/step - loss: 0.6943 - acc: 0.5012\n",
            "Epoch 4/20\n",
            "1600/1600 [==============================] - 28s 18ms/step - loss: 0.6939 - acc: 0.5046\n",
            "Epoch 5/20\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.6939 - acc: 0.5028\n",
            "Epoch 6/20\n",
            "1600/1600 [==============================] - 31s 20ms/step - loss: 0.6941 - acc: 0.4995\n",
            "Epoch 7/20\n",
            "1600/1600 [==============================] - 30s 19ms/step - loss: 0.6941 - acc: 0.5000\n",
            "Epoch 8/20\n",
            "1600/1600 [==============================] - 31s 19ms/step - loss: 0.6937 - acc: 0.5055\n",
            "Epoch 9/20\n",
            "1600/1600 [==============================] - 31s 19ms/step - loss: 0.6937 - acc: 0.5004\n",
            "Epoch 10/20\n",
            "1600/1600 [==============================] - 31s 19ms/step - loss: 0.6938 - acc: 0.5003\n",
            "Epoch 11/20\n",
            "1600/1600 [==============================] - 32s 20ms/step - loss: 0.6938 - acc: 0.5015\n",
            "Epoch 12/20\n",
            "1600/1600 [==============================] - 32s 20ms/step - loss: 0.6937 - acc: 0.5022\n",
            "Epoch 13/20\n",
            "1600/1600 [==============================] - 31s 19ms/step - loss: 0.6935 - acc: 0.5077\n",
            "Epoch 14/20\n",
            "1600/1600 [==============================] - 31s 19ms/step - loss: 0.6931 - acc: 0.5104\n",
            "Epoch 15/20\n",
            "1600/1600 [==============================] - 31s 19ms/step - loss: 0.6932 - acc: 0.5082\n",
            "Epoch 16/20\n",
            "1600/1600 [==============================] - 32s 20ms/step - loss: 0.6926 - acc: 0.5148\n",
            "Epoch 17/20\n",
            "1600/1600 [==============================] - 30s 19ms/step - loss: 0.6917 - acc: 0.5240\n",
            "Epoch 18/20\n",
            "1600/1600 [==============================] - 31s 20ms/step - loss: 0.6903 - acc: 0.5330\n",
            "Epoch 19/20\n",
            "1600/1600 [==============================] - 30s 19ms/step - loss: 0.6885 - acc: 0.5404\n",
            "Epoch 20/20\n",
            "1600/1600 [==============================] - 32s 20ms/step - loss: 0.6827 - acc: 0.5569\n",
            "500/500 [==============================] - 7s 14ms/step - loss: 0.6772 - acc: 0.5682\n",
            "\n",
            "test loss: 0.6771858930587769\n",
            "accuracy: 0.5681667327880859\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.6772 - acc: 0.5739\n",
            "\n",
            "train loss: 0.6772404909133911\n",
            "accuracy: 0.5739444494247437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel:  \n",
        "  def __init__(self):        \n",
        "    '''optimizer'''\n",
        "    # self.adam = Adam(lr=0.01)\n",
        "    # self.sgd = SGD(lr=0.01) \n",
        "    # self.model = Sequential()\n",
        "    pass\n",
        "\n",
        "  def modelBuild(self, filter, poolSize, kernelSize, unit):\n",
        "    # model = self.model\n",
        "    '''model build'''\n",
        "       \n",
        "    input = Input(shape=(1000, 4), name='input')\n",
        "    conv1d_1 = Conv1D(filters=filter, kernel_size=kernelSize, activation='tanh', name='conv1d_1')(input)\n",
        "    pool_1 = MaxPool1D(pool_size=poolSize, name='pool_1')(conv1d_1)\n",
        "    # conv1d_2 = Conv1D(filters=filter/2, kernel_size=kernelSize, activation='relu', name='conv1d_2')(pool_1)\n",
        "    # pool_2 = MaxPool1D(pool_size=2, name='pool_2')(conv1d_2)\n",
        "    goldpool_1 = GlobalMaxPool1D()(pool_1)\n",
        "    dense_1 = Dense(units=unit, activation='tanh', name='dense1')(goldpool_1)\n",
        "    # dense_2 = Dense(8, activation='relu', name='dense2')(dense_1)\n",
        "    output = Dense(1, activation='sigmoid', name='output')(dense_1)\n",
        "\n",
        "    model = Model(inputs=input, outputs=output)\n",
        "    return model\n",
        "\n",
        "  def modelCompile(self, opt, m):\n",
        "    '''model compile'''\n",
        "    model = m\n",
        "    model.compile(optimizer=opt,\n",
        "             metrics = 'acc',\n",
        "             loss = 'binary_crossentropy')\n",
        "\n",
        "  def modelFit(self, batSize, m): \n",
        "    '''model fix'''\n",
        "    model = m \n",
        "    # model = self.model \n",
        "    model.fit(x_train, \n",
        "              y_train,\n",
        "              epochs = 10,\n",
        "              batch_size = batSize\n",
        "              )\n",
        "    \n",
        "  def modelEvaluate(self, m):\n",
        "    '''model evaluate'''\n",
        "    model = m\n",
        "    # model = self.model\n",
        "    loss, accuracy1 = model.evaluate(x_train, y_train)\n",
        "    print(\"\\ntest loss:\", loss)\n",
        "    print('accuracy:', accuracy1)\n",
        "    \n",
        "    loss, accuracy2 = model.evaluate(x_test, y_test) #将我们的训练集也评估一下\n",
        "    print(\"\\ntrain loss:\", loss)\n",
        "    print('accuracy:', accuracy2)\n",
        "    \n",
        "    return \"test_loss\" + \"\\t\" + str(accuracy1) + \"\\t\" + \"train_loss\" + \"\\t\" + str(accuracy2)\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "  '''\n",
        "  1, Conv1d: Filters = {32, 16, 3}; Kernel_size = {20, 10, 7, 5, 3}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  2, Pooling1d: Max or Avg pool; Pool size = {8, 4, 2,}\n",
        "  3, Flatten: Global Max, Global Avg, Flatten\n",
        "  4, Dense: Units = {32, 64}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  '''\n",
        "  filter=[2, 4, 8, 16, 32, 64]  \n",
        "  kernel_size =[20, 10, 7, 5, 3]\n",
        "  poolSize = [8, 4, 2]\n",
        "  unit=[4, 8, 16, 32]\n",
        "  opt=['adam', 'sgd']\n",
        "  batSize=[4, 8, 10, 12]\n",
        "\n",
        "\n",
        "  from itertools import product\n",
        "#   outfile = open(\"outFileBinaryCrossentropy.txt\", \"a+\")\n",
        "  loop_val = [filter, kernel_size, poolSize, unit, opt, batSize] #\n",
        "  for i in product(*loop_val):\n",
        "    print(i)\n",
        "    chr_tmp = str(i)\n",
        "    # if i == (20, 'tanh', 2, 'tanh'):\n",
        "    outfile = open(\"outFileBC.txt\", \"a+\")\n",
        "    obj1 = CNNModel()\n",
        "    model = obj1.modelBuild(filter=i[0], kernelSize=i[1], poolSize=i[2], unit=i[3])\n",
        "    obj1.modelCompile(opt=i[4], m = model)\n",
        "    obj1.modelFit(batSize=i[5], m = model)\n",
        "    scor = obj1.modelEvaluate(m=model)\n",
        "    # print(scor)\n",
        "    outfile.write(chr_tmp + \"\\t\" + scor+\"\\n\")\n",
        "    outfile.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WWdrI29U7kO",
        "outputId": "d304c616-31b2-4a19-941f-145b14ae08a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 20, 8, 4, 'adam', 4)\n",
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 22s 5ms/step - loss: 0.6944 - acc: 0.5039\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.6937 - acc: 0.4945\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 22s 5ms/step - loss: 0.6933 - acc: 0.5014\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.6930 - acc: 0.5124\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.6920 - acc: 0.5181\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 22s 6ms/step - loss: 0.6914 - acc: 0.5222\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.6901 - acc: 0.5329\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 20s 5ms/step - loss: 0.6905 - acc: 0.5321\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.6892 - acc: 0.5343\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.6894 - acc: 0.5392\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6875 - acc: 0.5498\n",
            "\n",
            "test loss: 0.6875024437904358\n",
            "accuracy: 0.5498124957084656\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.6986 - acc: 0.4935\n",
            "\n",
            "train loss: 0.6985653042793274\n",
            "accuracy: 0.4934999942779541\n",
            "(2, 20, 8, 4, 'adam', 8)\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5803 - acc: 0.6753\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.3649 - acc: 0.8411\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3612 - acc: 0.8404\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.3603 - acc: 0.8439\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3591 - acc: 0.8428\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3582 - acc: 0.8436\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.3578 - acc: 0.8438\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3585 - acc: 0.8441\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3579 - acc: 0.8430\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.3577 - acc: 0.8433\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.3516 - acc: 0.8472\n",
            "\n",
            "test loss: 0.3515794575214386\n",
            "accuracy: 0.8472499847412109\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.3577 - acc: 0.8445\n",
            "\n",
            "train loss: 0.3576850891113281\n",
            "accuracy: 0.8445000052452087\n",
            "(2, 20, 8, 4, 'adam', 10)\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.4433 - acc: 0.7611\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1120 - acc: 0.9618\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.1084 - acc: 0.9618\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.1070 - acc: 0.9626\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1058 - acc: 0.9620\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.1055 - acc: 0.9634\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1052 - acc: 0.9629\n",
            "Epoch 8/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1048 - acc: 0.9618\n",
            "Epoch 9/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.1037 - acc: 0.9638\n",
            "Epoch 10/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1042 - acc: 0.9625\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.0990 - acc: 0.9659\n",
            "\n",
            "test loss: 0.09902670234441757\n",
            "accuracy: 0.9659374952316284\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0947 - acc: 0.9680\n",
            "\n",
            "train loss: 0.09467678517103195\n",
            "accuracy: 0.9679999947547913\n",
            "(2, 20, 8, 4, 'adam', 12)\n",
            "Epoch 1/10\n",
            "1334/1334 [==============================] - 15s 10ms/step - loss: 0.6937 - acc: 0.4976\n",
            "Epoch 2/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.6930 - acc: 0.5086\n",
            "Epoch 3/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.6929 - acc: 0.5084\n",
            "Epoch 4/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.6925 - acc: 0.5121\n",
            "Epoch 5/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.6915 - acc: 0.5309\n",
            "Epoch 6/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.6907 - acc: 0.5305\n",
            "Epoch 7/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.6896 - acc: 0.5376\n",
            "Epoch 8/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.6887 - acc: 0.5377\n",
            "Epoch 9/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.6879 - acc: 0.5444\n",
            "Epoch 10/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.6874 - acc: 0.5459\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.6849 - acc: 0.5555\n",
            "\n",
            "test loss: 0.6849400997161865\n",
            "accuracy: 0.5554999709129333\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.6962 - acc: 0.5115\n",
            "\n",
            "train loss: 0.6962015628814697\n",
            "accuracy: 0.5115000009536743\n",
            "(2, 20, 8, 4, 'sgd', 4)\n",
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 20s 5ms/step - loss: 0.5894 - acc: 0.6406\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 22s 6ms/step - loss: 0.1421 - acc: 0.9514\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.1351 - acc: 0.9528\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.1300 - acc: 0.9545\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.1269 - acc: 0.9569\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 22s 6ms/step - loss: 0.1267 - acc: 0.9559\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.1278 - acc: 0.9554\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 22s 5ms/step - loss: 0.1261 - acc: 0.9561\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.1242 - acc: 0.9572\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.1245 - acc: 0.9571\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1213 - acc: 0.9588\n",
            "\n",
            "test loss: 0.12128929048776627\n",
            "accuracy: 0.9587500095367432\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1229 - acc: 0.9610\n",
            "\n",
            "train loss: 0.12294352054595947\n",
            "accuracy: 0.9610000252723694\n",
            "(2, 20, 8, 4, 'sgd', 8)\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6956 - acc: 0.4968\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6934 - acc: 0.5071\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6936 - acc: 0.4942\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6934 - acc: 0.5033\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6924 - acc: 0.5149\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.4553 - acc: 0.8400\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1312 - acc: 0.9601\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1170 - acc: 0.9596\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1148 - acc: 0.9613\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1156 - acc: 0.9601\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1071 - acc: 0.9628\n",
            "\n",
            "test loss: 0.10714291781187057\n",
            "accuracy: 0.9627500176429749\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.0953 - acc: 0.9710\n",
            "\n",
            "train loss: 0.09525386244058609\n",
            "accuracy: 0.9710000157356262\n",
            "(2, 20, 8, 4, 'sgd', 10)\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.6938 - acc: 0.4985\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.6934 - acc: 0.4958\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.6935 - acc: 0.4961\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.6933 - acc: 0.4995\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.6934 - acc: 0.4984\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.6933 - acc: 0.5013\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.6935 - acc: 0.4971\n",
            "Epoch 8/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.6934 - acc: 0.4987\n",
            "Epoch 9/10\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.6933 - acc: 0.4997\n",
            "Epoch 10/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.6934 - acc: 0.5017\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.6938 - acc: 0.4997\n",
            "\n",
            "test loss: 0.6937881112098694\n",
            "accuracy: 0.4996874928474426\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.6933 - acc: 0.5060\n",
            "\n",
            "train loss: 0.6932924389839172\n",
            "accuracy: 0.5059999823570251\n",
            "(2, 20, 8, 4, 'sgd', 12)\n",
            "Epoch 1/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6936 - acc: 0.4950\n",
            "Epoch 2/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6935 - acc: 0.4992\n",
            "Epoch 3/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.6934 - acc: 0.5026\n",
            "Epoch 4/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6934 - acc: 0.5004\n",
            "Epoch 5/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6932 - acc: 0.5084\n",
            "Epoch 6/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6934 - acc: 0.4981\n",
            "Epoch 7/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.6934 - acc: 0.5009\n",
            "Epoch 8/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6934 - acc: 0.5023\n",
            "Epoch 9/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6933 - acc: 0.4994\n",
            "Epoch 10/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.6934 - acc: 0.5016\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6935 - acc: 0.4997\n",
            "\n",
            "test loss: 0.6935420036315918\n",
            "accuracy: 0.4996874928474426\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.6932 - acc: 0.5060\n",
            "\n",
            "train loss: 0.6931980848312378\n",
            "accuracy: 0.5059999823570251\n",
            "(2, 20, 8, 8, 'adam', 4)\n",
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 36s 9ms/step - loss: 0.6941 - acc: 0.4983\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 34s 9ms/step - loss: 0.6934 - acc: 0.5051\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 36s 9ms/step - loss: 0.6933 - acc: 0.5047\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 35s 9ms/step - loss: 0.6920 - acc: 0.5201\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 36s 9ms/step - loss: 0.6915 - acc: 0.5246\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.6905 - acc: 0.5338\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 35s 9ms/step - loss: 0.6896 - acc: 0.5336\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 35s 9ms/step - loss: 0.6890 - acc: 0.5391\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 37s 9ms/step - loss: 0.6886 - acc: 0.5392\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 35s 9ms/step - loss: 0.6882 - acc: 0.5404\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.6851 - acc: 0.5572\n",
            "\n",
            "test loss: 0.6850817799568176\n",
            "accuracy: 0.5571874976158142\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.6976 - acc: 0.5065\n",
            "\n",
            "train loss: 0.697601854801178\n",
            "accuracy: 0.5065000057220459\n",
            "(2, 20, 8, 8, 'adam', 8)\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.6937 - acc: 0.4969\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6936 - acc: 0.4979\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.6935 - acc: 0.5008\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6935 - acc: 0.4976\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6933 - acc: 0.5056\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.6922 - acc: 0.5147\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1991 - acc: 0.9261\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1200 - acc: 0.9584\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1177 - acc: 0.9590\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1164 - acc: 0.9601\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1115 - acc: 0.9617\n",
            "\n",
            "test loss: 0.11146479099988937\n",
            "accuracy: 0.9616875052452087\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1045 - acc: 0.9665\n",
            "\n",
            "train loss: 0.10452231764793396\n",
            "accuracy: 0.9664999842643738\n",
            "(2, 20, 8, 8, 'adam', 10)\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 17s 10ms/step - loss: 0.6937 - acc: 0.5033\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.6528 - acc: 0.5819\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 15s 10ms/step - loss: 0.3824 - acc: 0.8347\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.3744 - acc: 0.8363\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.3733 - acc: 0.8398\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.3729 - acc: 0.8397\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.3716 - acc: 0.8391\n",
            "Epoch 8/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.3712 - acc: 0.8389\n",
            "Epoch 9/10\n",
            "1600/1600 [==============================] - 17s 11ms/step - loss: 0.3718 - acc: 0.8393\n",
            "Epoch 10/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.3710 - acc: 0.8392\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.3703 - acc: 0.8409\n",
            "\n",
            "test loss: 0.37033581733703613\n",
            "accuracy: 0.8408750295639038\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.3839 - acc: 0.8270\n",
            "\n",
            "train loss: 0.38390734791755676\n",
            "accuracy: 0.8270000219345093\n",
            "(2, 20, 8, 8, 'adam', 12)\n",
            "Epoch 1/10\n",
            "1334/1334 [==============================] - 17s 12ms/step - loss: 0.6938 - acc: 0.5028\n",
            "Epoch 2/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.3863 - acc: 0.8048\n",
            "Epoch 3/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.1197 - acc: 0.9591\n",
            "Epoch 4/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.1171 - acc: 0.9586\n",
            "Epoch 5/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.1163 - acc: 0.9601\n",
            "Epoch 6/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.1161 - acc: 0.9589\n",
            "Epoch 7/10\n",
            "1334/1334 [==============================] - 15s 12ms/step - loss: 0.1157 - acc: 0.9594\n",
            "Epoch 8/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.1150 - acc: 0.9606\n",
            "Epoch 9/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.1147 - acc: 0.9599\n",
            "Epoch 10/10\n",
            "1334/1334 [==============================] - 16s 12ms/step - loss: 0.1129 - acc: 0.9613\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1131 - acc: 0.9606\n",
            "\n",
            "test loss: 0.11312844604253769\n",
            "accuracy: 0.9606249928474426\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.1107 - acc: 0.9655\n",
            "\n",
            "train loss: 0.11072155833244324\n",
            "accuracy: 0.965499997138977\n",
            "(2, 20, 8, 8, 'sgd', 4)\n",
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 23s 6ms/step - loss: 0.6944 - acc: 0.4967\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.6945 - acc: 0.4876\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.6942 - acc: 0.4969\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.6943 - acc: 0.4951\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 23s 6ms/step - loss: 0.6939 - acc: 0.5044\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 22s 6ms/step - loss: 0.6941 - acc: 0.4939\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.6941 - acc: 0.4981\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 22s 6ms/step - loss: 0.6941 - acc: 0.4964\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.6941 - acc: 0.4951\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 23s 6ms/step - loss: 0.6939 - acc: 0.4958\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.6941 - acc: 0.5003\n",
            "\n",
            "test loss: 0.6941227912902832\n",
            "accuracy: 0.5003125071525574\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.6947 - acc: 0.4940\n",
            "\n",
            "train loss: 0.6947111487388611\n",
            "accuracy: 0.49399998784065247\n",
            "(2, 20, 8, 8, 'sgd', 8)\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 18s 8ms/step - loss: 0.6929 - acc: 0.5081\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6049 - acc: 0.6744\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.1624 - acc: 0.9503\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1364 - acc: 0.9507\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1342 - acc: 0.9509\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.1338 - acc: 0.9524\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1332 - acc: 0.9523\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1329 - acc: 0.9542\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1314 - acc: 0.9542\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1320 - acc: 0.9534\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.1261 - acc: 0.9549\n",
            "\n",
            "test loss: 0.12612809240818024\n",
            "accuracy: 0.9548749923706055\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1211 - acc: 0.9590\n",
            "\n",
            "train loss: 0.12114309519529343\n",
            "accuracy: 0.9589999914169312\n",
            "(2, 20, 8, 8, 'sgd', 10)\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 17s 10ms/step - loss: 0.6936 - acc: 0.4953\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.6935 - acc: 0.4981\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.6935 - acc: 0.4963\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.6934 - acc: 0.4988\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.6935 - acc: 0.4959\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.6934 - acc: 0.5017\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.6933 - acc: 0.5039\n",
            "Epoch 8/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.6934 - acc: 0.4991\n",
            "Epoch 9/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.6933 - acc: 0.4994\n",
            "Epoch 10/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.6932 - acc: 0.5071\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.6939 - acc: 0.4997\n",
            "\n",
            "test loss: 0.6938683986663818\n",
            "accuracy: 0.4996874928474426\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.6936 - acc: 0.5060\n",
            "\n",
            "train loss: 0.6935832500457764\n",
            "accuracy: 0.5059999823570251\n",
            "(2, 20, 8, 8, 'sgd', 12)\n",
            "Epoch 1/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.7007 - acc: 0.5038\n",
            "Epoch 2/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6922 - acc: 0.5227\n",
            "Epoch 3/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.5380 - acc: 0.8051\n",
            "Epoch 4/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.1578 - acc: 0.9557\n",
            "Epoch 5/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.1250 - acc: 0.9574\n",
            "Epoch 6/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.1217 - acc: 0.9587\n",
            "Epoch 7/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.1208 - acc: 0.9583\n",
            "Epoch 8/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.1197 - acc: 0.9572\n",
            "Epoch 9/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.1203 - acc: 0.9580\n",
            "Epoch 10/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.1199 - acc: 0.9583\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.1143 - acc: 0.9614\n",
            "\n",
            "test loss: 0.11432038992643356\n",
            "accuracy: 0.9613749980926514\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1137 - acc: 0.9650\n",
            "\n",
            "train loss: 0.11372595280408859\n",
            "accuracy: 0.9649999737739563\n",
            "(2, 20, 8, 16, 'adam', 4)\n",
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 23s 6ms/step - loss: 0.6938 - acc: 0.5029\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.4168 - acc: 0.8174\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 23s 6ms/step - loss: 0.3775 - acc: 0.8348\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 23s 6ms/step - loss: 0.3760 - acc: 0.8367\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.3763 - acc: 0.8356\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.3761 - acc: 0.8371\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 26s 6ms/step - loss: 0.3753 - acc: 0.8381\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.3753 - acc: 0.8386\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.3745 - acc: 0.8371\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 23s 6ms/step - loss: 0.3743 - acc: 0.8375\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.3738 - acc: 0.8380\n",
            "\n",
            "test loss: 0.3738451898097992\n",
            "accuracy: 0.8379999995231628\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 0.3904 - acc: 0.8260\n",
            "\n",
            "train loss: 0.39036181569099426\n",
            "accuracy: 0.8259999752044678\n",
            "(2, 20, 8, 16, 'adam', 8)\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.4551 - acc: 0.7509\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2551 - acc: 0.8946\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.2517 - acc: 0.8981\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2426 - acc: 0.9035\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2239 - acc: 0.9133\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.2186 - acc: 0.9164\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2150 - acc: 0.9167\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.2126 - acc: 0.9190\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2083 - acc: 0.9201\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2090 - acc: 0.9216\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.2006 - acc: 0.9252\n",
            "\n",
            "test loss: 0.2006499022245407\n",
            "accuracy: 0.9251875281333923\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.2015 - acc: 0.9280\n",
            "\n",
            "train loss: 0.20146074891090393\n",
            "accuracy: 0.9279999732971191\n",
            "(2, 20, 8, 16, 'adam', 10)\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.5512 - acc: 0.6448\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1207 - acc: 0.9582\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1170 - acc: 0.9585\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.1165 - acc: 0.9586\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.1160 - acc: 0.9599\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1154 - acc: 0.9600\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.1142 - acc: 0.9606\n",
            "Epoch 8/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.1145 - acc: 0.9598\n",
            "Epoch 9/10\n",
            "1600/1600 [==============================] - 15s 10ms/step - loss: 0.1142 - acc: 0.9599\n",
            "Epoch 10/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1138 - acc: 0.9608\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.1089 - acc: 0.9625\n",
            "\n",
            "test loss: 0.10890857130289078\n",
            "accuracy: 0.9624999761581421\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1087 - acc: 0.9655\n",
            "\n",
            "train loss: 0.10870417952537537\n",
            "accuracy: 0.965499997138977\n",
            "(2, 20, 8, 16, 'adam', 12)\n",
            "Epoch 1/10\n",
            "1334/1334 [==============================] - 16s 11ms/step - loss: 0.6970 - acc: 0.5039\n",
            "Epoch 2/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.6929 - acc: 0.5126\n",
            "Epoch 3/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6927 - acc: 0.5116\n",
            "Epoch 4/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.6919 - acc: 0.5231\n",
            "Epoch 5/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6914 - acc: 0.5246\n",
            "Epoch 6/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6907 - acc: 0.5285\n",
            "Epoch 7/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.6906 - acc: 0.5263\n",
            "Epoch 8/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.6897 - acc: 0.5369\n",
            "Epoch 9/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.6890 - acc: 0.5386\n",
            "Epoch 10/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.6885 - acc: 0.5371\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.6860 - acc: 0.5474\n",
            "\n",
            "test loss: 0.6859502792358398\n",
            "accuracy: 0.5473750233650208\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.6961 - acc: 0.5150\n",
            "\n",
            "train loss: 0.6961026191711426\n",
            "accuracy: 0.5149999856948853\n",
            "(2, 20, 8, 16, 'sgd', 4)\n",
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.6945 - acc: 0.5004\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.6940 - acc: 0.5014\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.6941 - acc: 0.4939\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 28s 7ms/step - loss: 0.6938 - acc: 0.5014\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.6933 - acc: 0.5044\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.6921 - acc: 0.5179\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.2951 - acc: 0.8754\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.1319 - acc: 0.9532\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.1282 - acc: 0.9551\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.1278 - acc: 0.9559\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.1284 - acc: 0.9559\n",
            "\n",
            "test loss: 0.12842698395252228\n",
            "accuracy: 0.9558749794960022\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.1215 - acc: 0.9590\n",
            "\n",
            "train loss: 0.12146222591400146\n",
            "accuracy: 0.9589999914169312\n",
            "(2, 20, 8, 16, 'sgd', 8)\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6943 - acc: 0.4901\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6934 - acc: 0.5084\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.6934 - acc: 0.5058\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6935 - acc: 0.5023\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6934 - acc: 0.5031\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6933 - acc: 0.5057\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6935 - acc: 0.5039\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6934 - acc: 0.4977\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6935 - acc: 0.4979\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6933 - acc: 0.5048\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6932 - acc: 0.5006\n",
            "\n",
            "test loss: 0.6931825280189514\n",
            "accuracy: 0.5005624890327454\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.6936 - acc: 0.4935\n",
            "\n",
            "train loss: 0.6935752034187317\n",
            "accuracy: 0.4934999942779541\n",
            "(2, 20, 8, 16, 'sgd', 10)\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 16s 9ms/step - loss: 0.6946 - acc: 0.4981\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 15s 10ms/step - loss: 0.6938 - acc: 0.4965\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.6936 - acc: 0.4970\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.6939 - acc: 0.4936\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 15s 10ms/step - loss: 0.6936 - acc: 0.5017\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 15s 10ms/step - loss: 0.6937 - acc: 0.4990\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.6935 - acc: 0.5071\n",
            "Epoch 8/10\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.6935 - acc: 0.5023\n",
            "Epoch 9/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.6934 - acc: 0.5068\n",
            "Epoch 10/10\n",
            "1600/1600 [==============================] - 15s 10ms/step - loss: 0.6935 - acc: 0.4994\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.6930 - acc: 0.5024\n",
            "\n",
            "test loss: 0.6929895877838135\n",
            "accuracy: 0.5023750066757202\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.6933 - acc: 0.4940\n",
            "\n",
            "train loss: 0.6932856440544128\n",
            "accuracy: 0.49399998784065247\n",
            "(2, 20, 8, 16, 'sgd', 12)\n",
            "Epoch 1/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.6970 - acc: 0.4968\n",
            "Epoch 2/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.6931 - acc: 0.5063\n",
            "Epoch 3/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.5688 - acc: 0.7566\n",
            "Epoch 4/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.1564 - acc: 0.9576\n",
            "Epoch 5/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.1191 - acc: 0.9589\n",
            "Epoch 6/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.1156 - acc: 0.9589\n",
            "Epoch 7/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.1149 - acc: 0.9590\n",
            "Epoch 8/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.1139 - acc: 0.9595\n",
            "Epoch 9/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.1141 - acc: 0.9601\n",
            "Epoch 10/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.1135 - acc: 0.9606\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.1091 - acc: 0.9609\n",
            "\n",
            "test loss: 0.10907424986362457\n",
            "accuracy: 0.9609375\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.1001 - acc: 0.9690\n",
            "\n",
            "train loss: 0.10005126893520355\n",
            "accuracy: 0.968999981880188\n",
            "(2, 20, 8, 32, 'adam', 4)\n",
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 26s 6ms/step - loss: 0.6941 - acc: 0.5043\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.4903 - acc: 0.7380\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.3888 - acc: 0.8271\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.3877 - acc: 0.8286\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.3865 - acc: 0.8291\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.3869 - acc: 0.8282\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.3848 - acc: 0.8275\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 26s 6ms/step - loss: 0.3848 - acc: 0.8294\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.3847 - acc: 0.8311\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 26s 6ms/step - loss: 0.3832 - acc: 0.8303\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.3777 - acc: 0.8336\n",
            "\n",
            "test loss: 0.37768641114234924\n",
            "accuracy: 0.8336250185966492\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3770 - acc: 0.8350\n",
            "\n",
            "train loss: 0.3769930601119995\n",
            "accuracy: 0.8349999785423279\n",
            "(2, 20, 8, 32, 'adam', 8)\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6069 - acc: 0.5996\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.1728 - acc: 0.9363\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1689 - acc: 0.9383\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.1686 - acc: 0.9374\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1674 - acc: 0.9386\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.1673 - acc: 0.9382\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.1663 - acc: 0.9396\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1670 - acc: 0.9381\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.1663 - acc: 0.9389\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1657 - acc: 0.9389\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.1608 - acc: 0.9413\n",
            "\n",
            "test loss: 0.16078133881092072\n",
            "accuracy: 0.9412500262260437\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.1560 - acc: 0.9445\n",
            "\n",
            "train loss: 0.15601572394371033\n",
            "accuracy: 0.9445000290870667\n",
            "(2, 20, 8, 32, 'adam', 10)\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.2632 - acc: 0.8782\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 17s 10ms/step - loss: 0.1179 - acc: 0.9587\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1164 - acc: 0.9587\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1164 - acc: 0.9582\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1151 - acc: 0.9597\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1150 - acc: 0.9600\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1137 - acc: 0.9605\n",
            "Epoch 8/10\n",
            "1600/1600 [==============================] - 15s 10ms/step - loss: 0.1152 - acc: 0.9614\n",
            "Epoch 9/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1139 - acc: 0.9611\n",
            "Epoch 10/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1136 - acc: 0.9614\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.1093 - acc: 0.9619\n",
            "\n",
            "test loss: 0.10928260535001755\n",
            "accuracy: 0.9619374871253967\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1086 - acc: 0.9620\n",
            "\n",
            "train loss: 0.1086239367723465\n",
            "accuracy: 0.9620000123977661\n",
            "(2, 20, 8, 32, 'adam', 12)\n",
            "Epoch 1/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.6941 - acc: 0.4985\n",
            "Epoch 2/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.6577 - acc: 0.5676\n",
            "Epoch 3/10\n",
            "1334/1334 [==============================] - 13s 10ms/step - loss: 0.3920 - acc: 0.8261\n",
            "Epoch 4/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.3838 - acc: 0.8311\n",
            "Epoch 5/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.3832 - acc: 0.8319\n",
            "Epoch 6/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.3827 - acc: 0.8310\n",
            "Epoch 7/10\n",
            "1334/1334 [==============================] - 16s 12ms/step - loss: 0.3828 - acc: 0.8309\n",
            "Epoch 8/10\n",
            "1334/1334 [==============================] - 14s 11ms/step - loss: 0.3811 - acc: 0.8320\n",
            "Epoch 9/10\n",
            "1334/1334 [==============================] - 14s 10ms/step - loss: 0.3821 - acc: 0.8308\n",
            "Epoch 10/10\n",
            "1334/1334 [==============================] - 15s 11ms/step - loss: 0.3814 - acc: 0.8316\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.3778 - acc: 0.8329\n",
            "\n",
            "test loss: 0.377753883600235\n",
            "accuracy: 0.832937479019165\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.3783 - acc: 0.8305\n",
            "\n",
            "train loss: 0.37832680344581604\n",
            "accuracy: 0.8305000066757202\n",
            "(2, 20, 8, 32, 'sgd', 4)\n",
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.6946 - acc: 0.4989\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 26s 6ms/step - loss: 0.6944 - acc: 0.4994\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.6939 - acc: 0.5044\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 26s 6ms/step - loss: 0.6943 - acc: 0.4979\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.6938 - acc: 0.5067\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.6939 - acc: 0.5014\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.6936 - acc: 0.5056\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 23s 6ms/step - loss: 0.6935 - acc: 0.5042\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 25s 6ms/step - loss: 0.6934 - acc: 0.5064\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 24s 6ms/step - loss: 0.6929 - acc: 0.5116\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.6953 - acc: 0.5004\n",
            "\n",
            "test loss: 0.69533771276474\n",
            "accuracy: 0.500374972820282\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.6961 - acc: 0.5050\n",
            "\n",
            "train loss: 0.6960508227348328\n",
            "accuracy: 0.5049999952316284\n",
            "(2, 20, 8, 32, 'sgd', 8)\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.6941 - acc: 0.5047\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6938 - acc: 0.5009\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6938 - acc: 0.4942\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6937 - acc: 0.5023\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6938 - acc: 0.4974\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.6937 - acc: 0.5058\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6936 - acc: 0.5047\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.6935 - acc: 0.5095\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.6936 - acc: 0.5060\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6933 - acc: 0.5116\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.6939 - acc: 0.4999\n",
            "\n",
            "test loss: 0.69388347864151\n",
            "accuracy: 0.499875009059906\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.6944 - acc: 0.5060\n",
            "\n",
            "train loss: 0.6944034695625305\n",
            "accuracy: 0.5059999823570251\n",
            "(2, 20, 8, 32, 'sgd', 10)\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 16s 9ms/step - loss: 0.6941 - acc: 0.4983\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.6941 - acc: 0.4897\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.6938 - acc: 0.4985\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 15s 10ms/step - loss: 0.6938 - acc: 0.4959\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.6938 - acc: 0.4956\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.6938 - acc: 0.5008\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.6937 - acc: 0.5033\n",
            "Epoch 8/10\n",
            " 270/1600 [====>.........................] - ETA: 15s - loss: 0.6939 - acc: 0.4948"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://blog.csdn.net/w771792694/article/details/98182757"
      ],
      "metadata": {
        "id": "O1h_DqptBmR2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}