{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoB4lIs9Lzzf3iulR8aCcR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leiyi-ihb/ColabPractics/blob/main/lyProject/03_05_quiz_modelOptimization02.ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w8gysH9q1BNZ"
      },
      "outputs": [],
      "source": [
        "# We are going to optimize the quize model\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, MaxPooling1D, GlobalMaxPooling1D, Conv1D, Flatten, AveragePooling1D, GlobalAveragePooling1D\n",
        "from keras.optimizers import Adam, SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! -f \"dataset_Li.pkl\" ]; then wget https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl ; else echo \"Found previous downloaded data.\"; fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hKKfWYh1OKh",
        "outputId": "c2fe825d-f499-4334-908f-d90385ba18b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-07 16:03:18--  https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving master.dl.sourceforge.net (master.dl.sourceforge.net)... 216.105.38.12\n",
            "Connecting to master.dl.sourceforge.net (master.dl.sourceforge.net)|216.105.38.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl [following]\n",
            "--2022-11-07 16:03:19--  https://downloads.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving downloads.sourceforge.net (downloads.sourceforge.net)... 204.68.111.105\n",
            "Connecting to downloads.sourceforge.net (downloads.sourceforge.net)|204.68.111.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://jaist.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl [following]\n",
            "--2022-11-07 16:03:19--  https://jaist.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving jaist.dl.sourceforge.net (jaist.dl.sourceforge.net)... 150.65.7.130, 2001:df0:2ed:feed::feed\n",
            "Connecting to jaist.dl.sourceforge.net (jaist.dl.sourceforge.net)|150.65.7.130|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640080470 (610M) [application/octet-stream]\n",
            "Saving to: ‘dataset_Li.pkl’\n",
            "\n",
            "dataset_Li.pkl      100%[===================>] 610.43M  15.9MB/s    in 35s     \n",
            "\n",
            "2022-11-07 16:03:54 (17.6 MB/s) - ‘dataset_Li.pkl’ saved [640080470/640080470]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing\n",
        "import pickle\n",
        "with open(\"dataset_Li.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "x_train, y_train = np.array(data['train'][0]), np.array(data['train'][1])\n",
        "x_test, y_test = np.array(data['test'][0]), np.array(data['test'][1])\n",
        "\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8VNMGlB1Q0D",
        "outputId": "4f677a77-5c88-4d9b-970f-20b17889e337"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 1000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:  \n",
        "  def __init__(self, learnRate):        \n",
        "    '''optimizer'''\n",
        "    self.adam = Adam(lr=learnRate)\n",
        "    self.sgd = SGD(lr=learnRate) \n",
        "    self.model = Sequential()\n",
        "\n",
        "  def modelBuild(self, filter, poolSize, kernelSize, ConvAct, DenAct, input):\n",
        "    model = self.model\n",
        "    '''model build'''   \n",
        "    model.add(Conv1D(filters=filter, kernel_size=(kernelSize), activation=ConvAct, input_shape=input))\n",
        "    model.add(MaxPooling1D(pool_size=(poolSize)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32, activation=DenAct))\n",
        "    model.add(Dense(1, activation=DenAct))\n",
        "    print(model.summary())\n",
        "\n",
        "  def modelCompile(self, met, los):\n",
        "    '''model compile'''\n",
        "    model = self.model\n",
        "    model.compile(optimizer=self.adam,\n",
        "             metrics = [met],\n",
        "             loss = los)\n",
        "\n",
        "  def modelFit(self, xTrain, yTrain, epo, batSize): \n",
        "    '''model fix'''\n",
        "    model = self.model \n",
        "    model.fit(xTrain, \n",
        "              yTrain,\n",
        "              epochs = epo,\n",
        "              batch_size = batSize\n",
        "              )\n",
        "    \n",
        "  def modelEvaluate(self, xTrain, yTrain, xTest, yTest, batSize):\n",
        "    '''model evaluate'''\n",
        "    model = self.model\n",
        "    loss, accuracy = model.evaluate(xTrain, yTrain, batch_size=batSize)\n",
        "    print(\"\\ntest loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "    loss, accuracy = model.evaluate(xTest, yTest) #将我们的训练集也评估一下\n",
        "    print(\"\\ntrain loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "  '''\n",
        "  1, Conv1d: Filters = {32, 16, 3}; Kernel_size = {20, 10, 7, 5, 3}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  2, Pooling1d: Max or Avg pool; Pool size = {8, 4, 2,}\n",
        "  3, Flatten: Global Max, Global Avg, Flatten\n",
        "  4, Dense: Units = {32, 64}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  '''\n",
        "  kernel_size =[20, 10, 7, 5, 3]\n",
        "  activation = [\"relu\", \"tanh\", \"linear\"]\n",
        "  poolSize = [8, 4, 2]\n",
        "  deAct = [\"relu\", \"tanh\", \"linear\"]\n",
        "\n",
        "\n",
        "\n",
        "  obj1 = Model(0.01)\n",
        "  # obj1.modelBuild(filter=32, poolSize=i[2], kernelSize=i[0], ConvAct=i[1], DenAct=i[3], input=(1000, 4))\n",
        "  obj1.modelBuild(filter=32, poolSize=2, kernelSize=20, ConvAct=\"tanh\", DenAct=\"tanh\", input=(1000, 4))\n",
        "  obj1.modelCompile(met=\"acc\", los='binary_crossentropy')\n",
        "  obj1.modelFit(xTrain=x_train, yTrain=y_train, epo=10, batSize=512)\n",
        "  obj1.modelEvaluate(xTrain=x_train, yTrain=y_train, xTest=x_test, yTest=y_test, batSize=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swb572A41wyT",
        "outputId": "fc9d303b-cae8-47e0-e9c7-f3a32166936e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 981, 32)           2592      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 490, 32)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 32)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,681\n",
            "Trainable params: 3,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 16s 457ms/step - loss: 2.1674 - acc: 0.5008\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 14s 438ms/step - loss: 0.7337 - acc: 0.4964\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 14s 437ms/step - loss: 0.6780 - acc: 0.6183\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.5152 - acc: 0.8666\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 14s 438ms/step - loss: 0.2984 - acc: 0.9117\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 0.2951 - acc: 0.8930\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 0.2025 - acc: 0.9367\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.1632 - acc: 0.9481\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.1577 - acc: 0.9519\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.2835 - acc: 0.8945\n",
            "32/32 [==============================] - 4s 123ms/step - loss: 1.1203 - acc: 0.4997\n",
            "\n",
            "test loss: 1.1203430891036987\n",
            "accuracy: 0.4996874928474426\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 1.0988 - acc: 0.5060\n",
            "\n",
            "train loss: 1.0988444089889526\n",
            "accuracy: 0.5059999823570251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:  \n",
        "  def __init__(self, learnRate):        \n",
        "    '''optimizer'''\n",
        "    self.adam = Adam(lr=learnRate)\n",
        "    self.sgd = SGD(lr=learnRate) \n",
        "    self.model = Sequential()\n",
        "\n",
        "  def modelBuild(self, filter, poolSize, kernelSize, ConvAct, DenAct, input):\n",
        "    model = self.model\n",
        "    '''model build'''   \n",
        "    model.add(Conv1D(filters=filter, kernel_size=(kernelSize), activation=ConvAct, input_shape=input))\n",
        "    model.add(MaxPooling1D(pool_size=(poolSize)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Flatten())\n",
        "    # model.add(Dense(32, activation=DenAct))\n",
        "    model.add(Dense(1, activation=DenAct))\n",
        "    print(model.summary())\n",
        "\n",
        "  def modelCompile(self, met, los):\n",
        "    '''model compile'''\n",
        "    model = self.model\n",
        "    model.compile(optimizer=self.adam,\n",
        "             metrics = [met],\n",
        "             loss = los)\n",
        "\n",
        "  def modelFit(self, xTrain, yTrain, epo, batSize): \n",
        "    '''model fix'''\n",
        "    model = self.model \n",
        "    model.fit(xTrain, \n",
        "              yTrain,\n",
        "              epochs = epo,\n",
        "              batch_size = batSize\n",
        "              )\n",
        "    \n",
        "  def modelEvaluate(self, xTrain, yTrain, xTest, yTest, batSize):\n",
        "    '''model evaluate'''\n",
        "    model = self.model\n",
        "    loss, accuracy = model.evaluate(xTrain, yTrain, batch_size=batSize)\n",
        "    print(\"\\ntest loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "    loss, accuracy = model.evaluate(xTest, yTest) #将我们的训练集也评估一下\n",
        "    print(\"\\ntrain loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "  '''\n",
        "  1, Conv1d: Filters = {32, 16, 3}; Kernel_size = {20, 10, 7, 5, 3}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  2, Pooling1d: Max or Avg pool; Pool size = {8, 4, 2,}\n",
        "  3, Flatten: Global Max, Global Avg, Flatten\n",
        "  4, Dense: Units = {32, 64}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  '''\n",
        "  kernel_size =[20, 10, 7, 5, 3]\n",
        "  activation = [\"relu\", \"tanh\", \"linear\"]\n",
        "  poolSize = [8, 4, 2]\n",
        "  deAct = [\"relu\", \"tanh\", \"linear\"]\n",
        "\n",
        "\n",
        "\n",
        "  obj1 = Model(0.01)\n",
        "  # obj1.modelBuild(filter=32, poolSize=i[2], kernelSize=i[0], ConvAct=i[1], DenAct=i[3], input=(1000, 4))\n",
        "  obj1.modelBuild(filter=32, poolSize=2, kernelSize=20, ConvAct=\"tanh\", DenAct=\"tanh\", input=(1000, 4))\n",
        "  obj1.modelCompile(met=\"acc\", los='binary_crossentropy')\n",
        "  obj1.modelFit(xTrain=x_train, yTrain=y_train, epo=10, batSize=512)\n",
        "  obj1.modelEvaluate(xTrain=x_train, yTrain=y_train, xTest=x_test, yTest=y_test, batSize=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj9VDUL178oY",
        "outputId": "94a10674-4331-4e7e-9c9c-5d613b712e68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 981, 32)           2592      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 490, 32)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,625\n",
            "Trainable params: 2,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 15s 452ms/step - loss: 7.4718 - acc: 0.5017\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 15s 454ms/step - loss: 7.7077 - acc: 0.5003\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 7.7077 - acc: 0.5003\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 7.7077 - acc: 0.5003\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 15s 471ms/step - loss: 7.7077 - acc: 0.5003\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 7.7077 - acc: 0.5003\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 7.7077 - acc: 0.5003\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 7.7077 - acc: 0.5003\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 7.7077 - acc: 0.5003\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 7.7077 - acc: 0.5003\n",
            "32/32 [==============================] - 4s 123ms/step - loss: 7.7077 - acc: 0.5003\n",
            "\n",
            "test loss: 7.707653999328613\n",
            "accuracy: 0.5003125071525574\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 7.8050 - acc: 0.4940\n",
            "\n",
            "train loss: 7.805024147033691\n",
            "accuracy: 0.49399998784065247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:  \n",
        "  def __init__(self, learnRate):        \n",
        "    '''optimizer'''\n",
        "    self.adam = Adam(lr=learnRate)\n",
        "    self.sgd = SGD(lr=learnRate) \n",
        "    self.model = Sequential()\n",
        "\n",
        "  def modelBuild(self, filter, poolSize, kernelSize, ConvAct, DenAct, input):\n",
        "    model = self.model\n",
        "    '''model build'''   \n",
        "    model.add(Conv1D(filters=filter, kernel_size=(kernelSize), activation=ConvAct, input_shape=input))\n",
        "    model.add(MaxPooling1D(pool_size=(poolSize)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    # model.add(Flatten())\n",
        "    # model.add(Dense(32, activation=DenAct))\n",
        "    model.add(Dense(1, activation=DenAct))\n",
        "    print(model.summary())\n",
        "\n",
        "  def modelCompile(self, met, los):\n",
        "    '''model compile'''\n",
        "    model = self.model\n",
        "    model.compile(optimizer=self.adam,\n",
        "             metrics = [met],\n",
        "             loss = los)\n",
        "\n",
        "  def modelFit(self, xTrain, yTrain, epo, batSize): \n",
        "    '''model fix'''\n",
        "    model = self.model \n",
        "    model.fit(xTrain, \n",
        "              yTrain,\n",
        "              epochs = epo,\n",
        "              batch_size = batSize\n",
        "              )\n",
        "    \n",
        "  def modelEvaluate(self, xTrain, yTrain, xTest, yTest, batSize):\n",
        "    '''model evaluate'''\n",
        "    model = self.model\n",
        "    loss, accuracy = model.evaluate(xTrain, yTrain, batch_size=batSize)\n",
        "    print(\"\\ntest loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "    loss, accuracy = model.evaluate(xTest, yTest) #将我们的训练集也评估一下\n",
        "    print(\"\\ntrain loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "  '''\n",
        "  1, Conv1d: Filters = {32, 16, 3}; Kernel_size = {20, 10, 7, 5, 3}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  2, Pooling1d: Max or Avg pool; Pool size = {8, 4, 2,}\n",
        "  3, Flatten: Global Max, Global Avg, Flatten\n",
        "  4, Dense: Units = {32, 64}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  '''\n",
        "  kernel_size =[20, 10, 7, 5, 3]\n",
        "  activation = [\"relu\", \"tanh\", \"linear\"]\n",
        "  poolSize = [8, 4, 2]\n",
        "  deAct = [\"relu\", \"tanh\", \"linear\"]\n",
        "\n",
        "\n",
        "\n",
        "  obj1 = Model(0.01)\n",
        "  # obj1.modelBuild(filter=32, poolSize=i[2], kernelSize=i[0], ConvAct=i[1], DenAct=i[3], input=(1000, 4))\n",
        "  obj1.modelBuild(filter=32, poolSize=2, kernelSize=20, ConvAct=\"tanh\", DenAct=\"tanh\", input=(1000, 4))\n",
        "  obj1.modelCompile(met=\"acc\", los='binary_crossentropy')\n",
        "  obj1.modelFit(xTrain=x_train, yTrain=y_train, epo=10, batSize=512)\n",
        "  obj1.modelEvaluate(xTrain=x_train, yTrain=y_train, xTest=x_test, yTest=y_test, batSize=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l5RRn6p88Ct",
        "outputId": "a3155c27-c3d3-436f-cb93-2e9349892255"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 981, 32)           2592      \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 490, 32)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,625\n",
            "Trainable params: 2,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 15s 442ms/step - loss: 1.4785 - acc: 0.5010\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.7241 - acc: 0.4951\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.6846 - acc: 0.5493\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.6443 - acc: 0.7951\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.4472 - acc: 0.8908\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.2137 - acc: 0.9590\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 16s 489ms/step - loss: 0.1595 - acc: 0.9620\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 14s 439ms/step - loss: 0.1486 - acc: 0.9614\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.1768 - acc: 0.9479\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 14s 439ms/step - loss: 0.1626 - acc: 0.9549\n",
            "32/32 [==============================] - 4s 119ms/step - loss: 0.1375 - acc: 0.9586\n",
            "\n",
            "test loss: 0.13746315240859985\n",
            "accuracy: 0.9586250185966492\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 0.1384 - acc: 0.9665\n",
            "\n",
            "train loss: 0.13837851583957672\n",
            "accuracy: 0.9664999842643738\n"
          ]
        }
      ]
    }
  ]
}