{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxq5mvoNkNOW1epEQxTpSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leiyi-ihb/ColabPractics/blob/main/lyProject/03_04_quiz_modelOptimization03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hVs4MrepSF9m"
      },
      "outputs": [],
      "source": [
        "# validation the modles found from 03script\n",
        "# Solve the problem of different results showed in same model\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(1)  #The different tensorflow version have different code \n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, MaxPooling1D, GlobalMaxPooling1D, Conv1D, Flatten, AveragePooling1D, GlobalAveragePooling1D\n",
        "from keras.optimizers import Adam, SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**解决03_04脚本中结果不可重复的问题：**查阅[资料](https://www.jiqixuexishequ.com/how-to-use-keras-to-get-reproducible-results.html)在脚本【03_04_quiz_modelOptimization02.ipynb】中我们在脚本的最开始两行固定了随机数种子，但结果显示问题还是存在。因此我进一步将随机数种子固定在了建模开始处，这下发现每次运行结果都一样了。  \n",
        "`那我们进一步把开头固定的随机数种子去掉，又会有什么结果呢？？参阅脚本【03_04_quiz_modelOptimization04.ipynb】, 发现结果还是可重复的，说明脚本开始固定随机数没什么用`"
      ],
      "metadata": {
        "id": "wADpK_WBSN9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! -f \"dataset_Li.pkl\" ]; then wget https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl ; else echo \"Found previous downloaded data.\"; fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj3qor7eSbaW",
        "outputId": "8dba2813-473b-4023-849a-5b8f820fafe4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found previous downloaded data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing\n",
        "import pickle\n",
        "with open(\"dataset_Li.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "x_train, y_train = np.array(data['train'][0]), np.array(data['train'][1])\n",
        "x_test, y_test = np.array(data['test'][0]), np.array(data['test'][1])\n",
        "\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzXKUQ6vSe6T",
        "outputId": "dc88f12b-07c4-40cf-8502-1b9de0caa82d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 1000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model:\n",
        "  seed(1)\n",
        "  tensorflow.random.set_seed(1)  #最开始，我只在脚本开头设置了这个，没有在这里设置，发现问题还是存在，通过在这里设置之后，所有结果就很稳定了\n",
        "  def __init__(self, learnRate):        \n",
        "    '''optimizer'''\n",
        "    self.adam = Adam(lr=learnRate)\n",
        "    self.sgd = SGD(lr=learnRate) \n",
        "    self.model = Sequential()\n",
        "\n",
        "  def modelBuild(self, filter, poolSize, kernelSize, ConvAct, DenAct, input):\n",
        "    model = self.model\n",
        "    '''model build'''   \n",
        "    model.add(Conv1D(filters=filter, kernel_size=(kernelSize), activation=ConvAct, input_shape=input))\n",
        "    model.add(MaxPooling1D(pool_size=(poolSize)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32, activation=DenAct))\n",
        "    model.add(Dense(1, activation=DenAct))\n",
        "    print(model.summary())\n",
        "\n",
        "  def modelCompile(self, met, los):\n",
        "    '''model compile'''\n",
        "    model = self.model\n",
        "    model.compile(optimizer=self.adam,\n",
        "             metrics = [met],\n",
        "             loss = los)\n",
        "\n",
        "  def modelFit(self, xTrain, yTrain, epo, batSize): \n",
        "    '''model fix'''\n",
        "    model = self.model \n",
        "    model.fit(xTrain, \n",
        "              yTrain,\n",
        "              epochs = epo,\n",
        "              batch_size = batSize\n",
        "              )\n",
        "    \n",
        "  def modelEvaluate(self, xTrain, yTrain, xTest, yTest, batSize):\n",
        "    '''model evaluate'''\n",
        "    model = self.model\n",
        "    loss, accuracy = model.evaluate(xTrain, yTrain, batch_size=batSize)\n",
        "    print(\"\\ntest loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "    loss, accuracy = model.evaluate(xTest, yTest) #将我们的训练集也评估一下\n",
        "    print(\"\\ntrain loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "  '''\n",
        "  1, Conv1d: Filters = {32, 16, 3}; Kernel_size = {20, 10, 7, 5, 3}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  2, Pooling1d: Max or Avg pool; Pool size = {8, 4, 2,}\n",
        "  3, Flatten: Global Max, Global Avg, Flatten\n",
        "  4, Dense: Units = {32, 64}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  '''\n",
        "  kernel_size =[20, 10, 7, 5, 3]\n",
        "  activation = [\"relu\", \"tanh\", \"linear\"]\n",
        "  poolSize = [8, 4, 2]\n",
        "  deAct = [\"relu\", \"tanh\", \"linear\"]\n",
        "\n",
        "\n",
        "\n",
        "  obj1 = Model(0.01)\n",
        "  # obj1.modelBuild(filter=32, poolSize=i[2], kernelSize=i[0], ConvAct=i[1], DenAct=i[3], input=(1000, 4))\n",
        "  obj1.modelBuild(filter=32, poolSize=2, kernelSize=20, ConvAct=\"tanh\", DenAct=\"tanh\", input=(1000, 4))\n",
        "  obj1.modelCompile(met=\"acc\", los='binary_crossentropy')\n",
        "  obj1.modelFit(xTrain=x_train, yTrain=y_train, epo=10, batSize=512)\n",
        "  obj1.modelEvaluate(xTrain=x_train, yTrain=y_train, xTest=x_test, yTest=y_test, batSize=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbFSSO5-URaU",
        "outputId": "a49c2779-ce1c-4240-c555-c9d9ce258208"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_17 (Conv1D)          (None, 981, 32)           2592      \n",
            "                                                                 \n",
            " max_pooling1d_17 (MaxPoolin  (None, 490, 32)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " global_max_pooling1d_17 (Gl  (None, 32)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,681\n",
            "Trainable params: 3,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 10s 284ms/step - loss: 1.2812 - acc: 0.5028\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 9s 295ms/step - loss: 0.7095 - acc: 0.5083\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 9s 280ms/step - loss: 0.6909 - acc: 0.5289\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 9s 281ms/step - loss: 0.6148 - acc: 0.7866\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 9s 282ms/step - loss: 0.2468 - acc: 0.9426\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 9s 280ms/step - loss: 0.2675 - acc: 0.9355\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 9s 280ms/step - loss: 0.1865 - acc: 0.9499\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 9s 278ms/step - loss: 0.1594 - acc: 0.9566\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 9s 282ms/step - loss: 0.1423 - acc: 0.9615\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 9s 282ms/step - loss: 0.1293 - acc: 0.9608\n",
            "32/32 [==============================] - 2s 74ms/step - loss: 0.1226 - acc: 0.9624\n",
            "\n",
            "test loss: 0.12263466417789459\n",
            "accuracy: 0.9624375104904175\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1617 - acc: 0.9625\n",
            "\n",
            "train loss: 0.1617404669523239\n",
            "accuracy: 0.9624999761581421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model:\n",
        "  seed(1)\n",
        "  tensorflow.random.set_seed(1)  \n",
        "  def __init__(self, learnRate):        \n",
        "    '''optimizer'''\n",
        "    self.adam = Adam(lr=learnRate)\n",
        "    self.sgd = SGD(lr=learnRate) \n",
        "    self.model = Sequential()\n",
        "\n",
        "  def modelBuild(self, filter, poolSize, kernelSize, ConvAct, DenAct, input):\n",
        "    model = self.model\n",
        "    '''model build'''   \n",
        "    model.add(Conv1D(filters=filter, kernel_size=(kernelSize), activation=ConvAct, input_shape=input))\n",
        "    model.add(MaxPooling1D(pool_size=(poolSize)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32, activation=DenAct))\n",
        "    model.add(Dense(1, activation=DenAct))\n",
        "    print(model.summary())\n",
        "\n",
        "  def modelCompile(self, met, los):\n",
        "    '''model compile'''\n",
        "    model = self.model\n",
        "    model.compile(optimizer=self.adam,\n",
        "             metrics = [met],\n",
        "             loss = los)\n",
        "\n",
        "  def modelFit(self, xTrain, yTrain, epo, batSize): \n",
        "    '''model fix'''\n",
        "    model = self.model \n",
        "    model.fit(xTrain, \n",
        "              yTrain,\n",
        "              epochs = epo,\n",
        "              batch_size = batSize\n",
        "              )\n",
        "    \n",
        "  def modelEvaluate(self, xTrain, yTrain, xTest, yTest, batSize):\n",
        "    '''model evaluate'''\n",
        "    model = self.model\n",
        "    loss, accuracy = model.evaluate(xTrain, yTrain, batch_size=batSize)\n",
        "    print(\"\\ntest loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "    loss, accuracy = model.evaluate(xTest, yTest) #将我们的训练集也评估一下\n",
        "    print(\"\\ntrain loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "  '''\n",
        "  1, Conv1d: Filters = {32, 16, 3}; Kernel_size = {20, 10, 7, 5, 3}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  2, Pooling1d: Max or Avg pool; Pool size = {8, 4, 2,}\n",
        "  3, Flatten: Global Max, Global Avg, Flatten\n",
        "  4, Dense: Units = {32, 64}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  '''\n",
        "  kernel_size =[20, 10, 7, 5, 3]\n",
        "  activation = [\"relu\", \"tanh\", \"linear\"]\n",
        "  poolSize = [8, 4, 2]\n",
        "  deAct = [\"relu\", \"tanh\", \"linear\"]\n",
        "\n",
        "  from itertools import product\n",
        "  loop_val = [kernel_size, activation, poolSize, deAct] #\n",
        "  for i in product(*loop_val):\n",
        "    print(x_train.shape)\n",
        "    print(i)\n",
        "    if i == (20, 'tanh', 2, 'tanh'):\n",
        "      obj1 = Model(0.01)\n",
        "      obj1.modelBuild(filter=32, poolSize=i[2], kernelSize=i[0], ConvAct=i[1], DenAct=i[3], input=(1000, 4))\n",
        "      obj1.modelCompile(met=\"acc\", los='binary_crossentropy')\n",
        "      obj1.modelFit(xTrain=x_train, yTrain=y_train, epo=10, batSize=512)\n",
        "      obj1.modelEvaluate(xTrain=x_train, yTrain=y_train, xTest=x_test, yTest=y_test, batSize=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIcGb9KMUXpZ",
        "outputId": "6264689a-6922-40b5-98a5-9f00f1a96e3d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 1000, 4)\n",
            "(20, 'relu', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(20, 'relu', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(20, 'relu', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(20, 'relu', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(20, 'relu', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(20, 'relu', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(20, 'relu', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(20, 'relu', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(20, 'relu', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(20, 'tanh', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(20, 'tanh', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(20, 'tanh', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(20, 'tanh', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(20, 'tanh', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(20, 'tanh', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(20, 'tanh', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(20, 'tanh', 2, 'tanh')\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_12 (Conv1D)          (None, 981, 32)           2592      \n",
            "                                                                 \n",
            " max_pooling1d_12 (MaxPoolin  (None, 490, 32)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " global_max_pooling1d_12 (Gl  (None, 32)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,681\n",
            "Trainable params: 3,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 10s 287ms/step - loss: 1.2812 - acc: 0.5028\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 9s 287ms/step - loss: 0.7095 - acc: 0.5083\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 9s 284ms/step - loss: 0.6909 - acc: 0.5289\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 9s 284ms/step - loss: 0.6148 - acc: 0.7866\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 9s 284ms/step - loss: 0.2468 - acc: 0.9426\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 9s 287ms/step - loss: 0.2675 - acc: 0.9355\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 9s 286ms/step - loss: 0.1865 - acc: 0.9499\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 9s 286ms/step - loss: 0.1594 - acc: 0.9566\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 9s 287ms/step - loss: 0.1423 - acc: 0.9615\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 11s 335ms/step - loss: 0.1293 - acc: 0.9608\n",
            "32/32 [==============================] - 3s 71ms/step - loss: 0.1226 - acc: 0.9624\n",
            "\n",
            "test loss: 0.12263466417789459\n",
            "accuracy: 0.9624375104904175\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1617 - acc: 0.9625\n",
            "\n",
            "train loss: 0.1617404669523239\n",
            "accuracy: 0.9624999761581421\n",
            "(16000, 1000, 4)\n",
            "(20, 'tanh', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(20, 'linear', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(20, 'linear', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(20, 'linear', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(20, 'linear', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(20, 'linear', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(20, 'linear', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(20, 'linear', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(20, 'linear', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(20, 'linear', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(10, 'relu', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(10, 'relu', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(10, 'relu', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(10, 'relu', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(10, 'relu', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(10, 'relu', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(10, 'relu', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(10, 'relu', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(10, 'relu', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(10, 'tanh', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(10, 'tanh', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(10, 'tanh', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(10, 'tanh', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(10, 'tanh', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(10, 'tanh', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(10, 'tanh', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(10, 'tanh', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(10, 'tanh', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(10, 'linear', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(10, 'linear', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(10, 'linear', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(10, 'linear', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(10, 'linear', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(10, 'linear', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(10, 'linear', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(10, 'linear', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(10, 'linear', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(7, 'relu', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(7, 'relu', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(7, 'relu', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(7, 'relu', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(7, 'relu', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(7, 'relu', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(7, 'relu', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(7, 'relu', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(7, 'relu', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(7, 'tanh', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(7, 'tanh', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(7, 'tanh', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(7, 'tanh', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(7, 'tanh', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(7, 'tanh', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(7, 'tanh', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(7, 'tanh', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(7, 'tanh', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(7, 'linear', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(7, 'linear', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(7, 'linear', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(7, 'linear', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(7, 'linear', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(7, 'linear', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(7, 'linear', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(7, 'linear', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(7, 'linear', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(5, 'relu', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(5, 'relu', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(5, 'relu', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(5, 'relu', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(5, 'relu', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(5, 'relu', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(5, 'relu', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(5, 'relu', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(5, 'relu', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(5, 'tanh', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(5, 'tanh', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(5, 'tanh', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(5, 'tanh', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(5, 'tanh', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(5, 'tanh', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(5, 'tanh', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(5, 'tanh', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(5, 'tanh', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(5, 'linear', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(5, 'linear', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(5, 'linear', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(5, 'linear', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(5, 'linear', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(5, 'linear', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(5, 'linear', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(5, 'linear', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(5, 'linear', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(3, 'relu', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(3, 'relu', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(3, 'relu', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(3, 'relu', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(3, 'relu', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(3, 'relu', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(3, 'relu', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(3, 'relu', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(3, 'relu', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(3, 'tanh', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(3, 'tanh', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(3, 'tanh', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(3, 'tanh', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(3, 'tanh', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(3, 'tanh', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(3, 'tanh', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(3, 'tanh', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(3, 'tanh', 2, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(3, 'linear', 8, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(3, 'linear', 8, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(3, 'linear', 8, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(3, 'linear', 4, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(3, 'linear', 4, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(3, 'linear', 4, 'linear')\n",
            "(16000, 1000, 4)\n",
            "(3, 'linear', 2, 'relu')\n",
            "(16000, 1000, 4)\n",
            "(3, 'linear', 2, 'tanh')\n",
            "(16000, 1000, 4)\n",
            "(3, 'linear', 2, 'linear')\n"
          ]
        }
      ]
    }
  ]
}