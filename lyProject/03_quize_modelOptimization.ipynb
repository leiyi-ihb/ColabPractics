{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBbCH3p4n7qYPUKAT7pRqQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leiyi-ihb/ColabPractics/blob/main/lyProject/03_quize_modelOptimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mk096DBoiwgP"
      },
      "outputs": [],
      "source": [
        "# We are going to optimize the quize model\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, MaxPooling1D, GlobalMaxPooling1D, Conv1D, Flatten, AveragePooling1D, GlobalAveragePooling1D\n",
        "from keras.optimizers import Adam, SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! -f \"dataset_Li.pkl\" ]; then wget https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl ; else echo \"Found previous downloaded data.\"; fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyQN7S8_kLUV",
        "outputId": "21e1b8db-f74d-4fe4-da29-b70107559c02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-02 22:58:09--  https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving master.dl.sourceforge.net (master.dl.sourceforge.net)... 216.105.38.12\n",
            "Connecting to master.dl.sourceforge.net (master.dl.sourceforge.net)|216.105.38.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl [following]\n",
            "--2022-11-02 22:58:09--  https://downloads.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving downloads.sourceforge.net (downloads.sourceforge.net)... 204.68.111.105\n",
            "Connecting to downloads.sourceforge.net (downloads.sourceforge.net)|204.68.111.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://versaweb.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl [following]\n",
            "--2022-11-02 22:58:09--  https://versaweb.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving versaweb.dl.sourceforge.net (versaweb.dl.sourceforge.net)... 162.251.232.173\n",
            "Connecting to versaweb.dl.sourceforge.net (versaweb.dl.sourceforge.net)|162.251.232.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640080470 (610M) [application/octet-stream]\n",
            "Saving to: ‘dataset_Li.pkl’\n",
            "\n",
            "dataset_Li.pkl      100%[===================>] 610.43M  5.00MB/s    in 2m 2s   \n",
            "\n",
            "2022-11-02 23:00:12 (4.99 MB/s) - ‘dataset_Li.pkl’ saved [640080470/640080470]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing\n",
        "import pickle\n",
        "with open(\"dataset_Li.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "x_train, y_train = np.array(data['train'][0]), np.array(data['train'][1])\n",
        "x_test, y_test = np.array(data['test'][0]), np.array(data['test'][1])"
      ],
      "metadata": {
        "id": "Bk862UJakIAl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "class Model:\n",
        "  def __init__(self, learnRate):        \n",
        "    '''optimizer'''\n",
        "    self.adam = Adam(lr=learnRate)\n",
        "    self.sgd = SGD(lr=learnRate) \n",
        "\n",
        "  def modelBuild(self, filter, poolSize, kernelSize, ConvAct, DenAct, input):\n",
        "    '''model build'''    \n",
        "    model.add(Conv1D(filters=filter, kernel_size=(kernelSize), activation=ConvAct, input_shape=input))\n",
        "    model.add(MaxPooling1D(pool_size=(poolSize)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(1, activation=DenAct))\n",
        "    model.add(Dense(1, activation=DenAct))\n",
        "\n",
        "  def modelCompile(self, met, los):\n",
        "    '''model compile'''\n",
        "    model.compile(optimizer=self.sgd,\n",
        "             metrics = [met],\n",
        "             loss = los)\n",
        "\n",
        "  def modelFit(self, x_train, y_train, epo, batSize): \n",
        "    '''model fix'''\n",
        "    model.fit(x_train, \n",
        "              y_train,\n",
        "              epochs = epo,\n",
        "              batch_size = batSize,\n",
        "              validation_split = 0.2)\n",
        "    \n",
        "  def modelEvaluate(self, x_train, y_train, x_test, y_test, batSize):\n",
        "    '''model evaluate'''\n",
        "    loss, accuracy = model.evaluate(x_test, y_test, batch_size=batSize)\n",
        "    print(\"\\ntest loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "    loss, accuracy = model.evaluate(x_train, y_train) #将我们的训练集也评估一下\n",
        "    print(\"\\ntrain loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "  '''\n",
        "  1, Conv1d: Filters = {32, 16, 3}; Kernel_size = {20, 10, 7, 5, 3}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  2, Pooling1d: Max or Avg pool; Pool size = {8, 4, 2,}\n",
        "  3, Flatten: Global Max, Global Avg, Flatten\n",
        "  4, Dense: Units = {32, 64}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  '''\n",
        "  obj1 = Model(0.01)\n",
        "  obj1.modelBuild(32, 8, 20, \"relu\", \"sigmoid\", (1000, 4))\n",
        "  obj1.modelCompile(met=\"acc\", los='binary_crossentropy')\n",
        "  obj1.modelFit(x_train=x_train, y_train=y_train, epo=16, batSize=512)\n",
        "  obj1.modelEvaluate(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test, batSize=512)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7DZv_DzlBud",
        "outputId": "94175c37-3d8c-45f4-f5d0-2491f6d230c4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 7s 263ms/step - loss: 0.7070 - acc: 0.4983 - val_loss: 0.7033 - val_acc: 0.5053\n",
            "Epoch 2/16\n",
            "25/25 [==============================] - 6s 254ms/step - loss: 0.7042 - acc: 0.4983 - val_loss: 0.7011 - val_acc: 0.5053\n",
            "Epoch 3/16\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.7020 - acc: 0.4983 - val_loss: 0.6993 - val_acc: 0.5053\n",
            "Epoch 4/16\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.7002 - acc: 0.4983 - val_loss: 0.6979 - val_acc: 0.5053\n",
            "Epoch 5/16\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.6988 - acc: 0.4983 - val_loss: 0.6969 - val_acc: 0.5053\n",
            "Epoch 6/16\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.6977 - acc: 0.4983 - val_loss: 0.6960 - val_acc: 0.5053\n",
            "Epoch 7/16\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.6968 - acc: 0.4983 - val_loss: 0.6953 - val_acc: 0.5053\n",
            "Epoch 8/16\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.6961 - acc: 0.4983 - val_loss: 0.6948 - val_acc: 0.5053\n",
            "Epoch 9/16\n",
            "25/25 [==============================] - 7s 284ms/step - loss: 0.6955 - acc: 0.4983 - val_loss: 0.6944 - val_acc: 0.5053\n",
            "Epoch 10/16\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.6950 - acc: 0.4983 - val_loss: 0.6941 - val_acc: 0.5053\n",
            "Epoch 11/16\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.6946 - acc: 0.4983 - val_loss: 0.6938 - val_acc: 0.5053\n",
            "Epoch 12/16\n",
            "25/25 [==============================] - 6s 254ms/step - loss: 0.6943 - acc: 0.4983 - val_loss: 0.6936 - val_acc: 0.5053\n",
            "Epoch 13/16\n",
            "25/25 [==============================] - 6s 253ms/step - loss: 0.6941 - acc: 0.4983 - val_loss: 0.6934 - val_acc: 0.5053\n",
            "Epoch 14/16\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.6939 - acc: 0.4983 - val_loss: 0.6933 - val_acc: 0.5053\n",
            "Epoch 15/16\n",
            "25/25 [==============================] - 7s 287ms/step - loss: 0.6937 - acc: 0.4983 - val_loss: 0.6932 - val_acc: 0.5053\n",
            "Epoch 16/16\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.6936 - acc: 0.4983 - val_loss: 0.6932 - val_acc: 0.5053\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.6930 - acc: 0.5060\n",
            "\n",
            "test loss: 0.6930482387542725\n",
            "accuracy: 0.5059999823570251\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.6934 - acc: 0.4997\n",
            "\n",
            "train loss: 0.6934458017349243\n",
            "accuracy: 0.4996874928474426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://blog.csdn.net/w771792694/article/details/98182757"
      ],
      "metadata": {
        "id": "O1h_DqptBmR2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}