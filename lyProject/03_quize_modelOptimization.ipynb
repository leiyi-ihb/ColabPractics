{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi9h+CkNAaN9+7R2/jidI/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leiyi-ihb/ColabPractics/blob/main/lyProject/03_quize_modelOptimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mk096DBoiwgP"
      },
      "outputs": [],
      "source": [
        "# We are going to optimize the quize model\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, MaxPooling1D, GlobalMaxPooling1D, Conv1D, Flatten, AveragePooling1D, GlobalAveragePooling1D\n",
        "from keras.optimizers import Adam, SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! -f \"dataset_Li.pkl\" ]; then wget https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl ; else echo \"Found previous downloaded data.\"; fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyQN7S8_kLUV",
        "outputId": "21e1b8db-f74d-4fe4-da29-b70107559c02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-02 22:58:09--  https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving master.dl.sourceforge.net (master.dl.sourceforge.net)... 216.105.38.12\n",
            "Connecting to master.dl.sourceforge.net (master.dl.sourceforge.net)|216.105.38.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl [following]\n",
            "--2022-11-02 22:58:09--  https://downloads.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving downloads.sourceforge.net (downloads.sourceforge.net)... 204.68.111.105\n",
            "Connecting to downloads.sourceforge.net (downloads.sourceforge.net)|204.68.111.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://versaweb.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl [following]\n",
            "--2022-11-02 22:58:09--  https://versaweb.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving versaweb.dl.sourceforge.net (versaweb.dl.sourceforge.net)... 162.251.232.173\n",
            "Connecting to versaweb.dl.sourceforge.net (versaweb.dl.sourceforge.net)|162.251.232.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640080470 (610M) [application/octet-stream]\n",
            "Saving to: ‘dataset_Li.pkl’\n",
            "\n",
            "dataset_Li.pkl      100%[===================>] 610.43M  5.00MB/s    in 2m 2s   \n",
            "\n",
            "2022-11-02 23:00:12 (4.99 MB/s) - ‘dataset_Li.pkl’ saved [640080470/640080470]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing\n",
        "import pickle\n",
        "with open(\"dataset_Li.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "x_train, y_train = np.array(data['train'][0]), np.array(data['train'][1])\n",
        "x_test, y_test = np.array(data['test'][0]), np.array(data['test'][1])"
      ],
      "metadata": {
        "id": "Bk862UJakIAl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "class Model:\n",
        "  def __init__(self, learnRate):        \n",
        "    '''optimizer'''\n",
        "    self.adam = Adam(lr=learnRate)\n",
        "    self.sgd = SGD(lr=learnRate) \n",
        "\n",
        "  def modelBuild(self, filter, poolSize, kernelSize, ConvAct, DenAct, input):\n",
        "    '''model build'''    \n",
        "    model.add(Conv1D(filters=filter, kernel_size=(kernelSize), activation=ConvAct, input_shape=input))\n",
        "    model.add(MaxPooling1D(pool_size=(poolSize)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(1, activation=DenAct))\n",
        "    model.add(Dense(1, activation=DenAct))\n",
        "\n",
        "  def modelCompile(self, met, los):\n",
        "    '''model compile'''\n",
        "    model.compile(optimizer=self.sgd,\n",
        "             metrics = [met],\n",
        "             loss = los)\n",
        "\n",
        "  def modelFit(self, x_train, y_train, epo, batSize): \n",
        "    '''model fix'''\n",
        "    model.fit(x_train, \n",
        "              y_train,\n",
        "              epochs = epo,\n",
        "              batch_size = batSize,\n",
        "              validation_split = 0.2)\n",
        "    \n",
        "  def modelEvaluate(self, x_train, y_train, x_test, y_test, batSize):\n",
        "    '''model evaluate'''\n",
        "    loss, accuracy = model.evaluate(x_test, y_test, batch_size=batSize)\n",
        "    print(\"\\ntest loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "    loss, accuracy = model.evaluate(x_train, y_train) #将我们的训练集也评估一下\n",
        "    print(\"\\ntrain loss:\", loss)\n",
        "    print('accuracy:', accuracy)\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "  '''\n",
        "  1, Conv1d: Filters = {32, 16, 3}; Kernel_size = {20, 10, 7, 5, 3}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  2, Pooling1d: Max or Avg pool; Pool size = {8, 4, 2,}\n",
        "  3, Flatten: Global Max, Global Avg, Flatten\n",
        "  4, Dense: Units = {32, 64}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  '''\n",
        "  obj1 = Model(0.01)\n",
        "  obj1.modelBuild(32, 8, 20, \"relu\", \"sigmoid\", (1000, 4))\n",
        "  obj1.modelCompile(met=\"acc\", los='binary_crossentropy')\n",
        "  obj1.modelFit(x_train=x_train, y_train=y_train, epo=16, batSize=512)\n",
        "  obj1.modelEvaluate(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test, batSize=512)\n"
      ],
      "metadata": {
        "id": "C7DZv_DzlBud"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}