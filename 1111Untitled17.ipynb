{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLZma7wRAnEohSBfBFfZTr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leiyi-ihb/ColabPractics/blob/main/1111Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDDmkZNCFj-m",
        "outputId": "b816cf9f-80e6-4ef1-bf4d-583a1dfb5bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Platform:Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Tensorflow version:2.9.2\n",
            "Keras version:2.9.0\n"
          ]
        }
      ],
      "source": [
        "import platform\n",
        "import tensorflow\n",
        "import keras\n",
        "from numpy.random import seed\n",
        "print(\"Platform:{}\".format(platform.platform()))\n",
        "print(\"Tensorflow version:{}\".format(tensorflow.__version__))\n",
        "print(\"Keras version:{}\".format(keras.__version__))\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv1D, MaxPool1D\n",
        "from keras.utils import plot_model\n",
        "from keras.optimizers import Adam, SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! -f \"dataset_Li.pkl\" ]; then wget https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl ; else echo \"Found previous downloaded data.\"; fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qFlDEF9FmXF",
        "outputId": "523479c1-1c82-4e41-cd25-e8351136f5d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-11 23:46:39--  https://master.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving master.dl.sourceforge.net (master.dl.sourceforge.net)... 216.105.38.12\n",
            "Connecting to master.dl.sourceforge.net (master.dl.sourceforge.net)|216.105.38.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl [following]\n",
            "--2022-11-11 23:46:39--  https://downloads.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving downloads.sourceforge.net (downloads.sourceforge.net)... 204.68.111.105\n",
            "Connecting to downloads.sourceforge.net (downloads.sourceforge.net)|204.68.111.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://versaweb.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl [following]\n",
            "--2022-11-11 23:46:39--  https://versaweb.dl.sourceforge.net/project/summer-research-20/sim_data_1/dataset_Li.pkl\n",
            "Resolving versaweb.dl.sourceforge.net (versaweb.dl.sourceforge.net)... 162.251.232.173\n",
            "Connecting to versaweb.dl.sourceforge.net (versaweb.dl.sourceforge.net)|162.251.232.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640080470 (610M) [application/octet-stream]\n",
            "Saving to: ‘dataset_Li.pkl’\n",
            "\n",
            "dataset_Li.pkl      100%[===================>] 610.43M  5.09MB/s    in 2m 4s   \n",
            "\n",
            "2022-11-11 23:48:43 (4.94 MB/s) - ‘dataset_Li.pkl’ saved [640080470/640080470]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing\n",
        "import pickle\n",
        "with open(\"dataset_Li.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "x_train, y_train = np.array(data['train'][0]), np.array(data['train'][1])\n",
        "x_test, y_test = np.array(data['test'][0]), np.array(data['test'][1])\n",
        "\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WfH-TsHFo8M",
        "outputId": "cce32c73-0e12-41f1-92c0-4e0ce93b37cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 1000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.regularization.dropout import Dropout\n",
        "class CNNModel: \n",
        "  seed(1)\n",
        "  tensorflow.random.set_seed(1) \n",
        "  def __init__(self):        \n",
        "    '''optimizer'''\n",
        "    # self.adam = Adam(lr=0.01)\n",
        "    # self.sgd = SGD(lr=0.01) \n",
        "    # self.model = Sequential()\n",
        "    pass\n",
        "\n",
        "  def modelBuild(self, filter, poolSize, kernelSize, unit):\n",
        "    # model = self.model\n",
        "    '''model build'''\n",
        "       \n",
        "    input = Input(shape=(1000, 4), name='input')\n",
        "    conv1d_1 = Conv1D(filters=filter, kernel_size=kernelSize, activation='relu', name='conv1d_1')(input)\n",
        "    # pool_1 = MaxPool1D(pool_size=poolSize, name='pool_1')(conv1d_1)\n",
        "    conv1d_2 = Conv1D(filters=filter/2, kernel_size=kernelSize, activation='relu', name='conv1d_2')(conv1d_1)\n",
        "    # pool_2 = MaxPool1D(pool_size=2, name='pool_2')(conv1d_2)\n",
        "    conv1d_3 = Conv1D(filters=filter/4, kernel_size=kernelSize, activation='relu', name='conv1d_3')(conv1d_2)\n",
        "    pool_3 = MaxPool1D(pool_size=2, name='pool_3')(conv1d_3)\n",
        "    dense_1 = Dense(units=unit, activation='relu', name='dense1')(pool_3)\n",
        "    # dense_2 = Dense(8, activation='relu', name='dense2')(dense_1)\n",
        "    drop = Dropout(0.2, name='dropout_1')(dense_1)\n",
        "    output = Dense(1, name='output')(drop)\n",
        "\n",
        "    model = Model(inputs=input, outputs=output)\n",
        "    return model\n",
        "\n",
        "  def modelCompile(self, opt, m):\n",
        "    '''model compile'''\n",
        "    model = m\n",
        "    model.compile(optimizer=opt,\n",
        "             metrics = 'acc',\n",
        "             loss = 'binary_crossentropy')\n",
        "\n",
        "  def modelFit(self, batSize, m): \n",
        "    '''model fix'''\n",
        "    model = m \n",
        "    # model = self.model \n",
        "    model.fit(x_train, \n",
        "              y_train,\n",
        "              epochs = 100,\n",
        "              batch_size = batSize\n",
        "              )\n",
        "    \n",
        "  def modelEvaluate(self, m):\n",
        "    '''model evaluate'''\n",
        "    model = m\n",
        "    # model = self.model\n",
        "    loss, accuracy1 = model.evaluate(x_train, y_train)\n",
        "    print(\"\\ntest loss:\", loss)\n",
        "    print('accuracy:', accuracy1)\n",
        "    \n",
        "    loss, accuracy2 = model.evaluate(x_test, y_test) #将我们的训练集也评估一下\n",
        "    print(\"\\ntrain loss:\", loss)\n",
        "    print('accuracy:', accuracy2)\n",
        "    \n",
        "    return \"test_loss\" + \"\\t\" + str(accuracy1) + \"\\t\" + \"train_loss\" + \"\\t\" + str(accuracy2)\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "  '''\n",
        "  1, Conv1d: Filters = {32, 16, 3}; Kernel_size = {20, 10, 7, 5, 3}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  2, Pooling1d: Max or Avg pool; Pool size = {8, 4, 2,}\n",
        "  3, Flatten: Global Max, Global Avg, Flatten\n",
        "  4, Dense: Units = {32, 64}; Activation = {‘relu’, ‘tanh’, ‘linear’}\n",
        "  '''\n",
        "  filter=[4, 8, 16, 32, 64, 128]  \n",
        "  kernel_size =[20, 10, 7, 5, 53]\n",
        "  poolSize = [8, 4, 2]\n",
        "  unit=[4, 8, 16, 32]\n",
        "  opt=['adam', 'sgd']\n",
        "  batSize=[4, 8, 10, 12]\n",
        "\n",
        "\n",
        "  from itertools import product\n",
        "#   outfile = open(\"outFileBinaryCrossentropy.txt\", \"a+\")\n",
        "  loop_val = [filter, kernel_size, poolSize, unit, opt, batSize] #\n",
        "  for i in product(*loop_val):\n",
        "    # print(i)\n",
        "    chr_tmp = str(i)\n",
        "    if i == (4, 20, 8, 16, 'adam', 8):\n",
        "      outfile = open(\"outFileBC.txt\", \"a+\")\n",
        "      obj1 = CNNModel()\n",
        "      model = obj1.modelBuild(filter=i[0], kernelSize=i[1], poolSize=i[2], unit=i[3])\n",
        "      adam =Adam(lr=0.1)\n",
        "      obj1.modelCompile(opt=adam, m = model)\n",
        "      print(model.summary())\n",
        "      # obj1.modelFit(batSize=i[5], m = model)\n",
        "    #   scor = obj1.modelEvaluate(m=model)\n",
        "    # # print(scor)\n",
        "    #   outfile.write(chr_tmp + \"\\t\" + scor+\"\\n\")\n",
        "    #   outfile.close()\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ItLNwpFsC-",
        "outputId": "cfdfdc25-8c66-4ac9-a11a-652e4a9341f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000, 4)]         0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 981, 4)            324       \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 962, 2)            162       \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 943, 1)            41        \n",
            "                                                                 \n",
            " pool_3 (MaxPooling1D)       (None, 471, 1)            0         \n",
            "                                                                 \n",
            " dense1 (Dense)              (None, 471, 16)           32        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 471, 16)           0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 471, 1)            17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 576\n",
            "Trainable params: 576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}